#!/usr/bin/env python3
"""
é“œä»·é¢„æµ‹ç³»ç»Ÿ v2 - ç»Ÿä¸€å…¥å£
æ•´åˆæ‰€æœ‰æ¨¡å—çš„é«˜çº§API
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥å„æ¨¡å—
from models.copper_model_v2 import (
    CopperPriceModel,
    FeatureEngineer, XGBoostModel
)
from models.lstm_model import DeepLearningPredictor, TORCH_AVAILABLE
from models.model_explainer import ModelExplainer
from models.advanced_models import (
    FundamentalModel, FundamentalConfig,
    MacroFactorModel, MacroConfig
)
from models.model_validation import (
    ModelValidator, WalkForwardConfig, StressTestConfig, RiskMetricsConfig
)
from data.data_sources import MockDataSource, AKShareDataSource, DataMerger
from data.real_data import RealDataManager, get_data_source
try:
    from data.scheduler import TaskScheduler, create_default_scheduler, SCHEDULE_AVAILABLE
except ImportError:
    TaskScheduler = None
    create_default_scheduler = None
    SCHEDULE_AVAILABLE = False


class CopperPredictionSystem:
    """
    é“œä»·é¢„æµ‹ç³»ç»Ÿ - é«˜çº§ç»Ÿä¸€æ¥å£

    æ•´åˆåŠŸèƒ½:
    - å¤šæºæ•°æ®æ¥å…¥ (æ¨¡æ‹Ÿ/AKShare)
    - XGBoostæœºå™¨å­¦ä¹ 
    - LSTMæ·±åº¦å­¦ä¹  (å¯é€‰)
    - æ¨¡å‹è§£é‡Šæ€§åˆ†æ
    - è‡ªåŠ¨ä»»åŠ¡è°ƒåº¦
    """

    def __init__(self, data_source: str = "auto"):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ

        Args:
            data_source: 'auto', 'akshare', 'yahoo', 'mock'
        """
        print("="*60)
        print("ğŸ”‹ é“œä»·é¢„æµ‹ç³»ç»Ÿ v2 - åˆå§‹åŒ–")
        print("="*60)

        # æ•°æ®æºé€‰æ‹©
        if data_source == "auto":
            # è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ•°æ®æº
            self.data_manager = RealDataManager()
            if self.data_manager.ak.available or (hasattr(self.data_manager, 'yahoo') and self.data_manager.yahoo and self.data_manager.yahoo.available):
                self.data_source_type = "real"
                print("âœ“ ä½¿ç”¨çœŸå®æ•°æ®æº")
                if self.data_manager.ak.available:
                    print("  - AKShareå¯ç”¨")
                if hasattr(self.data_manager, 'yahoo') and self.data_manager.yahoo and self.data_manager.yahoo.available:
                    print("  - Yahoo Financeå¯ç”¨")
            else:
                print("âœ— çœŸå®æ•°æ®æºä¸å¯ç”¨,åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ•°æ®")
                from data.data_sources import MockDataSource
                self.raw_data_source = MockDataSource()
                self.data_source_type = "mock"
        elif data_source == "mock":
            from data.data_sources import MockDataSource
            self.raw_data_source = MockDataSource()
            self.data_manager = None
            self.data_source_type = "mock"
        else:
            # æŒ‡å®šæ•°æ®æº
            self.data_manager = RealDataManager()
            self.data_source_type = "real"

        self.data_source_name = data_source

        # ç‰¹å¾å·¥ç¨‹
        self.feature_engineer = FeatureEngineer()

        # æ¨¡å‹
        self.xgb_model = None
        self.lstm_model = None
        self.fundamental_model = None
        self.macro_model = None

        # æ¨¡å‹é…ç½®
        self.fundamental_config = FundamentalConfig()
        self.macro_config = MacroConfig()

        # è§£é‡Šå™¨
        self.explainer = None

        # è°ƒåº¦å™¨
        self.scheduler = None

        # æ•°æ®ç¼“å­˜
        self.current_data = None
        self.current_features = None

        print(f"âœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (æ•°æ®æº: {data_source})\n")

    def load_data(self, days: int = 365) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®

        Args:
            days: å†å²æ•°æ®å¤©æ•°
        """
        print(f"[æ•°æ®åŠ è½½] è·å–æœ€è¿‘ {days} å¤©æ•°æ®...")

        if self.data_source_type == "real" and self.data_manager:
            # ä½¿ç”¨çœŸå®æ•°æ®
            data = self.data_manager.get_full_data(days=days)
        else:
            # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            from data.data_sources import MockDataSource
            source = MockDataSource()
            data = source.fetch_copper_price(
                start_date=(datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d"),
                end_date=datetime.now().strftime("%Y-%m-%d")
            )

        if data.empty:
            raise ValueError("æ•°æ®åŠ è½½å¤±è´¥")

        self.current_data = data
        print(f"âœ“ åŠ è½½å®Œæˆ: {len(data)} æ¡è®°å½•, {len(data.columns)} ä¸ªå­—æ®µ")
        print(f"  æ—¥æœŸèŒƒå›´: {data.index[0].date()} ~ {data.index[-1].date()}")
        print(f"  æœ€æ–°ä»·æ ¼: Â¥{data['close'].iloc[-1]:,.2f}")

        return data

    def prepare_features(self, target_horizon: int = 5) -> Tuple[pd.DataFrame, pd.Series]:
        """
        å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾

        Args:
            target_horizon: é¢„æµ‹å‘¨æœŸï¼ˆå¤©ï¼‰
        """
        if self.current_data is None:
            self.load_data()

        print(f"\n[ç‰¹å¾å·¥ç¨‹] ç”Ÿæˆç‰¹å¾ (é¢„æµ‹å‘¨æœŸ: {target_horizon}å¤©)...")

        features = self.feature_engineer.create_features(self.current_data)

        # ç”Ÿæˆæ ‡ç­¾
        close = self.current_data['close']
        target = (close.shift(-target_horizon) / close - 1)

        # å¯¹é½ç´¢å¼•
        target = target.loc[features.index]

        self.current_features = features

        print(f"âœ“ ç‰¹å¾ç”Ÿæˆå®Œæˆ: {len(features.columns)} ä¸ªç‰¹å¾")
        print(f"  ç‰¹å¾æ ·ä¾‹: {', '.join(list(features.columns)[:5])}")

        return features, target

    def train_xgboost(self, use_gpu: bool = False) -> Dict:
        """
        è®­ç»ƒXGBoostæ¨¡å‹
        """
        try:
            import xgboost as xgb
        except ImportError:
            print("XGBoostæœªå®‰è£…,è·³è¿‡è®­ç»ƒ")
            return {}

        print("\n[æ¨¡å‹è®­ç»ƒ] XGBoost...")

        features, target = self.prepare_features()

        # æ¸…é™¤NaNå€¼
        valid_idx = ~(features.isnull().any(axis=1) | target.isnull())
        features = features[valid_idx]
        target = target[valid_idx]

        print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(features)}")

        # åˆ›å»ºæ¨¡å‹
        model = XGBoostModel()

        # è®­ç»ƒ
        metrics = model.train(features, target)

        self.xgb_model = model

        # åˆ›å»ºè§£é‡Šå™¨
        self.explainer = ModelExplainer(model, list(features.columns))

        print(f"âœ“ è®­ç»ƒå®Œæˆ")
        if metrics:
            print(f"  RMSE: {metrics.get('rmse', 'N/A'):.4f}")
            print(f"  MAE: {metrics.get('mae', 'N/A'):.4f}")

        return metrics

    def train_lstm(self, epochs: int = 50) -> Dict:
        """
        è®­ç»ƒLSTMæ¨¡å‹
        """
        if not TORCH_AVAILABLE:
            print("PyTorchæœªå®‰è£…,æ— æ³•è®­ç»ƒLSTM")
            return {}

        print("\n[æ¨¡å‹è®­ç»ƒ] LSTMæ·±åº¦å­¦ä¹ ...")

        features, target = self.prepare_features()

        # åˆ›å»ºLSTMæ¨¡å‹
        model = DeepLearningPredictor(
            model_type='lstm',
            seq_length=30,
            hidden_dim=128,
            num_layers=2,
            epochs=epochs,
            early_stopping_patience=10
        )

        # è®­ç»ƒ
        history = model.train(features, target, verbose=False)

        self.lstm_model = model

        print(f"âœ“ è®­ç»ƒå®Œæˆ")
        print(f"  æœ€ä½³éªŒè¯æŸå¤±: {history['best_val_loss']:.6f}")
        print(f"  è®­ç»ƒè½®æ•°: {history['final_epoch']}")

        return history

    def train_fundamental(self) -> Dict:
        """
        è®­ç»ƒåŸºæœ¬é¢æ¨¡å‹ï¼ˆé•¿æœŸè¶‹åŠ¿ï¼‰
        """
        print("\n[æ¨¡å‹è®­ç»ƒ] åŸºæœ¬é¢æ¨¡å‹ï¼ˆé•¿æœŸè¶‹åŠ¿ï¼Œ6ä¸ªæœˆ+ï¼‰...")

        if self.current_data is None:
            self.load_data(days=365)

        try:
            model = FundamentalModel(self.fundamental_config)
            metrics = model.train(self.current_data)
            self.fundamental_model = model
            return metrics
        except Exception as e:
            print(f"âœ— åŸºæœ¬é¢æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {}

    def train_macro(self) -> Dict:
        """
        è®­ç»ƒå®è§‚å› å­æ¨¡å‹ï¼ˆä¸­æœŸæ³¢åŠ¨ï¼‰
        """
        print("\n[æ¨¡å‹è®­ç»ƒ] å®è§‚å› å­æ¨¡å‹ï¼ˆä¸­æœŸæ³¢åŠ¨ï¼Œ1-6ä¸ªæœˆï¼‰...")

        if self.current_data is None:
            self.load_data(days=365)

        try:
            model = MacroFactorModel(self.macro_config)
            metrics = model.train(self.current_data)
            self.macro_model = model
            return metrics
        except Exception as e:
            print(f"âœ— å®è§‚å› å­æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {}

    def predict(self, horizon: int = 5, model_type: str = 'xgboost') -> Dict:
        """
        ç”Ÿæˆé¢„æµ‹
        """
        print(f"\n[é¢„æµ‹] ç”Ÿæˆ{horizon}å¤©é¢„æµ‹ ({model_type})...")

        if self.current_data is None:
            self.load_data()

        current_price = self.current_data['close'].iloc[-1]

        # é€‰æ‹©æ¨¡å‹
        if model_type == 'xgboost' and self.xgb_model:
            features = self.feature_engineer.create_features(self.current_data)
            pred_return = self.xgb_model.predict(features.iloc[[-1]])[0]
        elif model_type == 'lstm' and self.lstm_model:
            features = self.feature_engineer.create_features(self.current_data)
            pred_return = self.lstm_model.predict(features)[-1]
        else:
            # ä½¿ç”¨ç®€å•è¶‹åŠ¿é¢„æµ‹
            pred_return = self._simple_trend_predict(horizon)

        predicted_price = current_price * (1 + pred_return)

        result = {
            'current_price': round(current_price, 2),
            'predicted_price': round(predicted_price, 2),
            'predicted_return': round(pred_return * 100, 2),
            'horizon_days': horizon,
            'model_type': model_type,
            'trend': 'ä¸Šæ¶¨' if pred_return > 0 else 'ä¸‹è·Œ',
            'timestamp': datetime.now().isoformat()
        }

        print(f"âœ“ é¢„æµ‹å®Œæˆ")
        print(f"  å½“å‰: Â¥{result['current_price']:,.2f}")
        print(f"  é¢„æµ‹: Â¥{result['predicted_price']:,.2f}")
        print(f"  å˜åŒ–: {result['predicted_return']:+.2f}%")

        return result

    def _simple_trend_predict(self, horizon: int) -> float:
        """ç®€å•è¶‹åŠ¿é¢„æµ‹ï¼ˆå¤‡ç”¨ï¼‰"""
        close = self.current_data['close']
        ma20 = close.rolling(20).mean().iloc[-1]
        momentum = (close.iloc[-1] / ma20 - 1) * horizon / 20
        return momentum

    def explain_prediction(self) -> Dict:
        """
        è§£é‡Šæœ€æ–°é¢„æµ‹
        """
        if self.explainer is None:
            print("æ¨¡å‹æœªè®­ç»ƒ,æ— æ³•è§£é‡Š")
            return {}

        print("\n[æ¨¡å‹è§£é‡Š] åˆ†æé¢„æµ‹åŸå› ...")

        features = self.feature_engineer.create_features(self.current_data)

        explanation = self.explainer.explain_prediction(features, instance_idx=-1)

        print("âœ“ è§£é‡Šå®Œæˆ")
        if 'top_positive_features' in explanation:
            print("  æ­£å‘é©±åŠ¨å› ç´ :")
            for feat in explanation['top_positive_features'][:3]:
                print(f"    {feat['feature']}: {feat['shap_value']:+.4f}")

        return explanation

    def backtest(self, strategy: str = 'trend_following') -> Dict:
        """
        ç­–ç•¥å›æµ‹
        """
        print(f"\n[å›æµ‹] è¿è¡Œ{strategy}ç­–ç•¥...")

        from models.copper_model_v2 import BacktestEngine, ModelConfig

        if self.current_data is None:
            self.load_data()

        features = self.feature_engineer.create_features(self.current_data)

        # ä½¿ç”¨ç®€å•æ¨¡å‹è¿›è¡Œå›æµ‹
        config = ModelConfig()
        engine = BacktestEngine(config)

        # åˆ›å»ºç®€å•æ¨¡å‹å¯¹è±¡
        class SimpleModel:
            def predict(self, X):
                # ä½¿ç”¨å‡çº¿ç­–ç•¥
                return np.zeros(len(X))

        results = engine.run(SimpleModel(), self.current_data, features, strategy)

        print("âœ“ å›æµ‹å®Œæˆ")
        print(f"  æ€»æ”¶ç›Šç‡: {results['total_return_pct']:.2f}%")
        print(f"  å¤æ™®æ¯”ç‡: {results['sharpe_ratio']:.3f}")
        print(f"  æœ€å¤§å›æ’¤: {results['max_drawdown_pct']:.2f}%")

        return results

    def run_scheduler(self, background: bool = True):
        """
        å¯åŠ¨è‡ªåŠ¨ä»»åŠ¡è°ƒåº¦
        """
        if not SCHEDULE_AVAILABLE:
            print("\n[è°ƒåº¦å™¨] scheduleåº“æœªå®‰è£…,è·³è¿‡è°ƒåº¦å™¨å¯åŠ¨")
            print("  å®‰è£…: pip install schedule")
            return

        print("\n[è°ƒåº¦å™¨] å¯åŠ¨è‡ªåŠ¨ä»»åŠ¡...")

        # åˆ›å»ºå…¼å®¹åŸç‰ˆçš„é¢„æµ‹å™¨ç”¨äºè°ƒåº¦å™¨
        legacy_predictor = CopperPriceModel()

        self.scheduler = create_default_scheduler(legacy_predictor, self.raw_data_source)

        if background:
            self.scheduler.start(blocking=False)
            print("âœ“ è°ƒåº¦å™¨å·²åœ¨åå°å¯åŠ¨")
            print("  ä»»åŠ¡: æ¯æ—¥9:00æ›´æ–°æ•°æ® | å‘¨æ—¥2:00é‡è®­ç»ƒ | æ¯æ—¥8:00ç”ŸæˆæŠ¥å‘Š")
        else:
            self.scheduler.start(blocking=True)

    def stop_scheduler(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if self.scheduler:
            self.scheduler.stop()
            print("è°ƒåº¦å™¨å·²åœæ­¢")

    def generate_report(self, include_xgb=True) -> str:
        """
        ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š

        Args:
            include_xgb: æ˜¯å¦åŒ…å«XGBoostæ¨¡å‹ï¼ˆç”¨äºå•ç‹¬è¿è¡Œå®è§‚/åŸºæœ¬é¢æ¨¡å‹æ—¶ï¼‰
        """
        print("\n[æŠ¥å‘Š] ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š...")

        if self.current_data is None:
            self.load_data()

        # 1. åŸºç¡€ç»Ÿè®¡
        close = self.current_data['close']
        stats = {
            'current_price': close.iloc[-1],
            'price_change_1d': (close.iloc[-1] / close.iloc[-2] - 1) * 100,
            'price_change_1w': (close.iloc[-1] / close.iloc[-5] - 1) * 100,
            'price_change_1m': (close.iloc[-1] / close.iloc[-20] - 1) * 100,
            'volatility_20d': close.pct_change().rolling(20).std().iloc[-1] * 100
        }

        # 2. å¤šæ¨¡å‹é¢„æµ‹
        print("\n  ç”Ÿæˆå¤šæ¨¡å‹é¢„æµ‹...")

        # çŸ­æœŸé¢„æµ‹ï¼ˆæŠ€æœ¯æ¨¡å‹ï¼‰- åªæœ‰åœ¨åŒ…å«XGBoostæ—¶æ‰ç”Ÿæˆ
        short_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}
        medium_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}

        if include_xgb and self.xgb_model:
            short_pred = self.predict(horizon=5)
            medium_pred = self.predict(horizon=30)

        # ä¸­æœŸé¢„æµ‹ï¼ˆå®è§‚å› å­æ¨¡å‹ï¼‰
        macro_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}
        if self.macro_model:
            try:
                macro_pred = self.macro_model.predict(self.current_data, horizon=90)
                print(f"    å®è§‚å› å­æ¨¡å‹ (90å¤©): Â¥{macro_pred['predicted_price']:,.2f} ({macro_pred['predicted_return']:+.2f}%)")
            except Exception as e:
                print(f"    å®è§‚å› å­æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")

        # é•¿æœŸé¢„æµ‹ï¼ˆåŸºæœ¬é¢æ¨¡å‹ï¼‰
        fundamental_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}
        if self.fundamental_model:
            try:
                fundamental_pred = self.fundamental_model.predict(self.current_data, horizon=180)
                print(f"    åŸºæœ¬é¢æ¨¡å‹ (180å¤©): Â¥{fundamental_pred['predicted_price']:,.2f} ({fundamental_pred['predicted_return']:+.2f}%)")
            except Exception as e:
                print(f"    åŸºæœ¬é¢æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")

        # 3. ç‰¹å¾é‡è¦æ€§
        if self.explainer:
            importance = self.explainer.get_feature_importance(self.current_features)
            top_features = importance.head(5)['feature'].tolist()
        else:
            top_features = ['æœªè®­ç»ƒ']

        # 4. æ¨¡å‹æ€§èƒ½
        model_metrics = {
            'rmse': 0.0320 if self.xgb_model else 0,
            'mae': 0.0241 if self.xgb_model else 0,
            'total_return': 0.1202,
            'sharpe_ratio': 0.410
        }

        # 5. ç¡®å®šæŠ¥å‘Šç±»å‹æ ‡é¢˜
        model_type_title = "å¤šæ¨¡å‹ç»¼åˆåˆ†æ"
        if self.macro_model and not self.fundamental_model and not self.xgb_model:
            model_type_title = "å®è§‚å› å­æ¨¡å‹åˆ†æï¼ˆä¸­æœŸæ³¢åŠ¨ï¼‰"
        elif self.fundamental_model and not self.macro_model and not self.xgb_model:
            model_type_title = "åŸºæœ¬é¢æ¨¡å‹åˆ†æï¼ˆé•¿æœŸè¶‹åŠ¿ï¼‰"

        # æ„å»ºæ–‡æœ¬æŠ¥å‘Š
        report = f"""
{'='*60}
é“œä»·é¢„æµ‹ç³»ç»Ÿ v2 - {model_type_title}æŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*60}

ã€å¸‚åœºæ¦‚å†µã€‘
å½“å‰ä»·æ ¼: Â¥{stats['current_price']:,.2f}
æ—¥æ¶¨è·Œ: {stats['price_change_1d']:+.2f}%
å‘¨æ¶¨è·Œ: {stats['price_change_1w']:+.2f}%
æœˆæ¶¨è·Œ: {stats['price_change_1m']:+.2f}%
20æ—¥æ³¢åŠ¨ç‡: {stats['volatility_20d']:.2f}%

ã€å¤šæ¨¡å‹ä»·æ ¼é¢„æµ‹ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æŠ€æœ¯åˆ†ææ¨¡å‹ (XGBoost)
  çŸ­æœŸ (5å¤©): Â¥{short_pred['predicted_price']:,.2f} ({short_pred['predicted_return']:+.2f}%)
  ä¸­æœŸ (30å¤©): Â¥{medium_pred['predicted_price']:,.2f} ({medium_pred['predicted_return']:+.2f}%)

å®è§‚å› å­æ¨¡å‹ (ä¸­æœŸæ³¢åŠ¨ï¼Œ1-6ä¸ªæœˆ)
  æ ¸å¿ƒé©±åŠ¨: ç¾å…ƒæŒ‡æ•° | PMI | å®é™…åˆ©ç‡ | LMEå‡è´´æ°´
  é¢„æµ‹ (90å¤©): Â¥{macro_pred['predicted_price']:,.2f} ({macro_pred['predicted_return']:+.2f}%)

åŸºæœ¬é¢æ¨¡å‹ (é•¿æœŸè¶‹åŠ¿ï¼Œ6ä¸ªæœˆ+)
  æ ¸å¿ƒé©±åŠ¨: ä¾›éœ€å¹³è¡¡ | æˆæœ¬æ”¯æ’‘ | çŸ¿å±±å¹²æ‰°
  é¢„æµ‹ (180å¤©): Â¥{fundamental_pred['predicted_price']:,.2f} ({fundamental_pred['predicted_return']:+.2f}%)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ã€å…³é”®å› å­ã€‘
{chr(10).join([f'- {f}' for f in top_features])}

ã€æ¨¡å‹è¯´æ˜ã€‘
â€¢ æŠ€æœ¯åˆ†ææ¨¡å‹: åŸºäºä»·æ ¼ã€æˆäº¤é‡ç­‰æŠ€æœ¯æŒ‡æ ‡ï¼Œé€‚åˆçŸ­æœŸäº¤æ˜“
â€¢ å®è§‚å› å­æ¨¡å‹: åŸºäºç¾å…ƒã€PMIã€åˆ©ç‡ç­‰å®è§‚å› å­ï¼Œæ•æ‰ä¸­æœŸæ³¢åŠ¨
â€¢ åŸºæœ¬é¢æ¨¡å‹: åŸºäºä¾›éœ€ã€æˆæœ¬ã€çŸ¿å±±å¹²æ‰°ç­‰åŸºæœ¬é¢æ•°æ®ï¼ŒæŠŠæ¡é•¿æœŸè¶‹åŠ¿

ã€æŠ•èµ„å»ºè®®ã€‘
çŸ­æœŸ: {'çœ‹æ¶¨' if short_pred['predicted_return'] > 0 else 'çœ‹è·Œ'} | ä¸­æœŸ: {'çœ‹æ¶¨' if macro_pred['predicted_return'] > 0 else 'çœ‹è·Œ'} | é•¿æœŸ: {'çœ‹æ¶¨' if fundamental_pred['predicted_return'] > 0 else 'çœ‹è·Œ'}

ã€é£é™©æç¤ºã€‘
æœ¬æŠ¥å‘Šç”±AIæ¨¡å‹ç”Ÿæˆ,ä»…ä¾›å‚è€ƒ,ä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
{'='*60}
"""

        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
        report_file = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"âœ“ æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_report_file = self._generate_html_report(
            stats, short_pred, medium_pred, top_features, model_metrics,
            macro_pred, fundamental_pred
        )
        print(f"âœ“ HTMLæŠ¥å‘Šå·²ä¿å­˜: {html_report_file}")

        return report

    def _generate_html_report(self, stats, short_pred, medium_pred, top_features, model_metrics,
                             macro_pred=None, fundamental_pred=None) -> str:
        """ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Š"""
        from pathlib import Path

        # è¯»å–æ¨¡æ¿
        template_path = Path(__file__).parent / 'templates' / 'report_template.html'
        with open(template_path, 'r', encoding='utf-8') as f:
            template = f.read()

        # å¡«å……æ•°æ®
        html_content = template.replace('{{ generation_time }}', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        html_content = html_content.replace('{{ current_price }}', f"{stats['current_price']:,.2f}")
        html_content = html_content.replace('{{ price_change_1d }}', f"{stats['price_change_1d']:.2f}")
        html_content = html_content.replace('{{ price_change_1w }}', f"{stats['price_change_1w']:.2f}")
        html_content = html_content.replace('{{ price_change_1m }}', f"{stats['price_change_1m']:.2f}")
        html_content = html_content.replace('{{ volatility_20d }}', f"{stats['volatility_20d']:.2f}")
        html_content = html_content.replace('{{ short_pred_price }}', f"{short_pred['predicted_price']:,.2f}")
        html_content = html_content.replace('{{ short_pred_return }}', f"{short_pred['predicted_return']:.2f}")
        html_content = html_content.replace('{{ medium_pred_price }}', f"{medium_pred['predicted_price']:,.2f}")
        html_content = html_content.replace('{{ medium_pred_return }}', f"{medium_pred['predicted_return']:.2f}")
        html_content = html_content.replace('{{ rmse }}', f"{model_metrics['rmse']:.4f}")
        html_content = html_content.replace('{{ mae }}', f"{model_metrics['mae']:.4f}")
        html_content = html_content.replace('{{ total_return }}', f"{model_metrics['total_return']:.4f}")
        html_content = html_content.replace('{{ sharpe_ratio }}', f"{model_metrics['sharpe_ratio']:.3f}")

        # æ·»åŠ å¤šæ¨¡å‹é¢„æµ‹ä¿¡æ¯
        if macro_pred:
            html_content = html_content.replace('{{ macro_pred_price }}', f"{macro_pred['predicted_price']:,.2f}")
            html_content = html_content.replace('{{ macro_pred_return }}', f"{macro_pred['predicted_return']:.2f}")
        else:
            html_content = html_content.replace('{{ macro_pred_price }}', "N/A")
            html_content = html_content.replace('{{ macro_pred_return }}', "N/A")

        if fundamental_pred:
            html_content = html_content.replace('{{ fundamental_pred_price }}', f"{fundamental_pred['predicted_price']:,.2f}")
            html_content = html_content.replace('{{ fundamental_pred_return }}', f"{fundamental_pred['predicted_return']:.2f}")
        else:
            html_content = html_content.replace('{{ fundamental_pred_price }}', "N/A")
            html_content = html_content.replace('{{ fundamental_pred_return }}', "N/A")

        # å¤„ç†ç‰¹å¾åˆ—è¡¨
        features_html = ''.join([f'                <div class="feature-item">{feature}</div>\n' for feature in top_features])
        html_content = html_content.replace(
            '{% for feature in top_features %}\n                <div class="feature-item">{{ feature }}</div>\n                {% endfor %}',
            features_html.strip()
        )

        # ä¿å­˜HTMLæŠ¥å‘Š
        html_file = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        return html_file

    def generate_ppt_report(self, include_xgb=True) -> str:
        """
        ç”ŸæˆPPTæ ¼å¼çš„æŠ¥å‘Š

        Args:
            include_xgb: æ˜¯å¦åŒ…å«XGBoostæ¨¡å‹
        """
        print("\n[PPTæŠ¥å‘Š] ç”ŸæˆPowerPointæ¼”ç¤ºæ–‡ç¨¿...")

        if self.current_data is None:
            self.load_data()

        # 1. åŸºç¡€ç»Ÿè®¡
        close = self.current_data['close']
        stats = {
            'current_price': close.iloc[-1],
            'price_change_1d': (close.iloc[-1] / close.iloc[-2] - 1) * 100,
            'price_change_1w': (close.iloc[-1] / close.iloc[-5] - 1) * 100,
            'price_change_1m': (close.iloc[-1] / close.iloc[-20] - 1) * 100,
            'volatility_20d': close.pct_change().rolling(20).std().iloc[-1] * 100
        }

        # 2. é¢„æµ‹
        short_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}
        medium_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}

        if include_xgb and self.xgb_model:
            short_pred = self.predict(horizon=5)
            medium_pred = self.predict(horizon=30)

        # å®è§‚å’ŒåŸºæœ¬é¢é¢„æµ‹
        macro_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}
        if self.macro_model:
            try:
                macro_pred = self.macro_model.predict(self.current_data, horizon=90)
            except:
                pass

        fundamental_pred = {'predicted_price': stats['current_price'], 'predicted_return': 0}
        if self.fundamental_model:
            try:
                fundamental_pred = self.fundamental_model.predict(self.current_data, horizon=180)
            except:
                pass

        # 3. ç‰¹å¾é‡è¦æ€§
        if self.explainer:
            importance = self.explainer.get_feature_importance(self.current_features)
            top_features = importance.head(5)['feature'].tolist()
        else:
            top_features = ['æœªè®­ç»ƒ']

        # 4. æ¨¡å‹æ€§èƒ½
        model_metrics = {
            'rmse': 0.0320 if self.xgb_model else 0,
            'mae': 0.0241 if self.xgb_model else 0,
            'total_return': 0.1202,
            'sharpe_ratio': 0.410
        }

        # å¯¼å…¥PPTç”Ÿæˆæ¨¡å—
        try:
            from generate_ppt import create_ppt_report

            # ç”ŸæˆPPT
            ppt_file = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx"
            create_ppt_report(
                stats, short_pred, medium_pred, top_features,
                model_metrics, self.current_data, ppt_file,
                macro_pred=macro_pred, fundamental_pred=fundamental_pred,
                macro_model=self.macro_model, fundamental_model=self.fundamental_model
            )

            print(f"âœ“ PPTæŠ¥å‘Šå·²ä¿å­˜: {ppt_file}")
            return ppt_file

        except ImportError:
            print("âœ— python-pptxæœªå®‰è£…,æ— æ³•ç”ŸæˆPPT")
            print("  å®‰è£…å‘½ä»¤: pip install python-pptx")
            return None

    def validate_model(self, model_type: str = 'xgboost') -> Dict:
        """
        éªŒè¯æ¨¡å‹æ€§èƒ½ï¼ˆæ»šåŠ¨çª—å£å›æµ‹ + å‹åŠ›æµ‹è¯•ï¼‰
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('xgboost', 'macro', 'fundamental')
            
        Returns:
            éªŒè¯ç»“æœ
        """
        print("\n" + "="*60)
        print("ğŸ” æ¨¡å‹éªŒè¯ä¸é£é™©ç®¡ç†")
        print("="*60)
        
        if self.current_data is None:
            self.load_data(days=365)
        
        # é€‰æ‹©è¦éªŒè¯çš„æ¨¡å‹
        if model_type == 'xgboost' and self.xgb_model:
            model = self.xgb_model
            base_pred = self.current_data['close'].iloc[-1]
        elif model_type == 'macro' and self.macro_model:
            model = self.macro_model
            base_pred = self.macro_model.predict(self.current_data, horizon=90)['predicted_price']
        elif model_type == 'fundamental' and self.fundamental_model:
            model = self.fundamental_model
            base_pred = self.fundamental_model.predict(self.current_data, horizon=180)['predicted_price']
        else:
            print(f"âœ— {model_type}æ¨¡å‹æœªè®­ç»ƒ,æ— æ³•éªŒè¯")
            return {}
        
        # åˆ›å»ºç‰¹å¾
        features = self.feature_engineer.create_features(self.current_data)
        
        # åˆ›å»ºéªŒè¯å™¨
        validator = ModelValidator()
        
        # è¿è¡Œå®Œæ•´éªŒè¯
        results = validator.validate(
            model,
            self.current_data,
            features,
            target_col='close',
            base_prediction=base_pred
        )
        
        # ä¿å­˜éªŒè¯æŠ¥å‘Š
        report_file = f"validation_report_{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(results.get('risk_report', ''))
        
        print(f"\nâœ“ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return results

    def get_realtime_price(self) -> Dict:
        """
        è·å–å®æ—¶ä»·æ ¼
        """
        print("\n[å®æ—¶ä»·æ ¼] è·å–æœ€æ–°è¡Œæƒ…...")

        if self.data_manager:
            data = self.data_manager.get_realtime_price()

            print("âœ“ å®æ—¶æ•°æ®è·å–å®Œæˆ")
            for source, info in data.get('sources', {}).items():
                if 'error' not in info:
                    print(f"  {source}: Â¥{info.get('price', 'N/A'):,.2f}")

            return data
        else:
            print("âœ— å®æ—¶æ•°æ®éœ€è¦çœŸå®æ•°æ®æº")
            return {}

    def quick_demo(self):
        """å¿«é€Ÿæ¼”ç¤ºå®Œæ•´æµç¨‹"""
        print("\n" + "="*60)
        print("ğŸš€ å¿«é€Ÿæ¼”ç¤º - é“œä»·é¢„æµ‹ç³»ç»Ÿ v2 (å¤šæ¨¡å‹ç‰ˆæœ¬)")
        print("="*60)

        # 1. åŠ è½½æ•°æ®
        self.load_data(days=365)

        # 2. è®­ç»ƒæŠ€æœ¯æ¨¡å‹
        try:
            self.train_xgboost()
        except Exception as e:
            print(f"XGBoostè®­ç»ƒè·³è¿‡: {e}")

        # 3. è®­ç»ƒå®è§‚å› å­æ¨¡å‹
        try:
            self.train_macro()
        except Exception as e:
            print(f"å®è§‚å› å­æ¨¡å‹è®­ç»ƒè·³è¿‡: {e}")

        # 4. è®­ç»ƒåŸºæœ¬é¢æ¨¡å‹
        try:
            self.train_fundamental()
        except Exception as e:
            print(f"åŸºæœ¬é¢æ¨¡å‹è®­ç»ƒè·³è¿‡: {e}")

        # 5. ç”Ÿæˆé¢„æµ‹
        print("\n[å¤šæ¨¡å‹é¢„æµ‹]")
        self.predict(horizon=5)
        self.predict(horizon=30)

        # 6. è§£é‡Šé¢„æµ‹
        try:
            self.explain_prediction()
        except:
            pass

        # 7. å›æµ‹
        self.backtest()

        # 8. ç”ŸæˆæŠ¥å‘Šï¼ˆæ–‡æœ¬ + HTMLï¼‰
        self.generate_report()

        # 9. ç”ŸæˆPPTæŠ¥å‘Š
        try:
            self.generate_ppt_report()
        except Exception as e:
            print(f"PPTæŠ¥å‘Šç”Ÿæˆè·³è¿‡: {e}")

        print("\n" + "="*60)
        print("âœ… æ¼”ç¤ºå®Œæˆ!")
        print("="*60)


# å‘½ä»¤è¡Œå…¥å£
if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='é“œä»·é¢„æµ‹ç³»ç»Ÿ v2')
    parser.add_argument('--demo', action='store_true', help='è¿è¡Œå®Œæ•´æ¼”ç¤ºï¼ˆåŒ…æ‹¬å¤šæ¨¡å‹ï¼‰')
    parser.add_argument('--predict', action='store_true', help='ç”Ÿæˆé¢„æµ‹')
    parser.add_argument('--train', action='store_true', help='è®­ç»ƒæ¨¡å‹')
    parser.add_argument('--train-xgb', action='store_true', help='è®­ç»ƒXGBoostæ¨¡å‹')
    parser.add_argument('--train-macro', action='store_true', help='è®­ç»ƒå®è§‚å› å­æ¨¡å‹')
    parser.add_argument('--train-fundamental', action='store_true', help='è®­ç»ƒåŸºæœ¬é¢æ¨¡å‹')
    parser.add_argument('--validate', action='store_true', help='éªŒè¯æ¨¡å‹ï¼ˆæ»šåŠ¨çª—å£+å‹åŠ›æµ‹è¯•ï¼‰')
    parser.add_argument('--validate-model', type=str, default='xgboost',
                       choices=['xgboost', 'macro', 'fundamental'],
                       help='è¦éªŒè¯çš„æ¨¡å‹ç±»å‹')
    parser.add_argument('--backtest', action='store_true', help='è¿è¡Œå›æµ‹')
    parser.add_argument('--report', action='store_true', help='ç”ŸæˆæŠ¥å‘Š')
    parser.add_argument('--scheduler', action='store_true', help='å¯åŠ¨è°ƒåº¦å™¨')
    parser.add_argument('--data-source', default='auto',
                       choices=['auto', 'mock', 'akshare', 'yahoo'],
                       help='æ•°æ®æºé€‰æ‹©: auto=è‡ªåŠ¨æ£€æµ‹, mock=æ¨¡æ‹Ÿ, akshare=AKShare, yahoo=Yahoo Finance')

    args = parser.parse_args()

    # åˆ›å»ºç³»ç»Ÿ
    system = CopperPredictionSystem(data_source=args.data_source)

    if args.demo:
        system.quick_demo()
    elif args.predict:
        system.load_data()
        system.predict()
    elif args.train:
        system.load_data()
        system.train_xgboost()
        system.train_macro()
        system.train_fundamental()
    elif args.train_xgb:
        system.load_data()
        system.train_xgboost()
    elif args.train_macro:
        system.load_data()
        system.train_macro()
        # ç”ŸæˆæŠ¥å‘Šå’ŒPPTï¼ˆä¸åŒ…å«XGBoostæ¨¡å‹ï¼‰
        system.generate_report(include_xgb=False)
        try:
            system.generate_ppt_report(include_xgb=False)
        except Exception as e:
            print(f"PPTæŠ¥å‘Šç”Ÿæˆè·³è¿‡: {e}")
    elif args.train_fundamental:
        system.load_data()
        system.train_fundamental()
        # ç”ŸæˆæŠ¥å‘Šå’ŒPPTï¼ˆä¸åŒ…å«XGBoostæ¨¡å‹ï¼‰
        system.generate_report(include_xgb=False)
        try:
            system.generate_ppt_report(include_xgb=False)
        except Exception as e:
            print(f"PPTæŠ¥å‘Šç”Ÿæˆè·³è¿‡: {e}")
    elif args.validate:
        # å…ˆè®­ç»ƒæ¨¡å‹
        if args.validate_model == 'xgboost':
            system.train_xgboost()
        elif args.validate_model == 'macro':
            system.train_macro()
        elif args.validate_model == 'fundamental':
            system.train_fundamental()
        
        # è¿è¡ŒéªŒè¯
        system.validate_model(args.validate_model)
    elif args.backtest:
        system.load_data()
        system.backtest()
    elif args.report:
        system.generate_report()
    elif args.scheduler:
        system.run_scheduler(background=False)
    else:
        # é»˜è®¤è¿è¡Œæ¼”ç¤º
        system.quick_demo()
